# The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits

Shuming Ma, Hongyu Wang, Lingxiao Ma, Lei Wang, Wenhui Wang, Shaohan Huang, Li Dong, Ruiping Wang, Jilong Xue, Furu Wei

# arXiv Paper

The paper for 1 bit LLM can be found here - [1 bit LLMs](https://arxiv.org/abs/2310.11453)
The paper for BitNet can be found here - [BitNet](https://arxiv.org/abs/2310.11453)

# Slides

The link to the google slides can be found here - [link](https://docs.google.com/presentation/d/1_n6zs-ATyhV2552immpT9vp38aY1xLRDqBsGAv7SRX0/edit#slide=id.g2c07449bc5b_0_35)

# References

https://huggingface.co/papers/2402.17764  
https://medium.com/data-science-in-your-pocket/what-are-1-bit-llms-3f2ae4b40fdf  
https://www.youtube.com/watch?v=ZpxQec_3t38
